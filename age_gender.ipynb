{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72bf7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6277e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-i'], dest='i', nargs=None, const=None, default=None, type=None, choices=None, help='Path to input image or video file. Skip this argument to capture frames from a camera.', metavar=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Use this script to run age and gender recognition using OpenCV.')\n",
    "parser.add_argument(\"-i\", help='Path to input image or video file. Skip this argument to capture frames from a camera.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa0be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a01c630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c83f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b01de9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "563155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "ageNet = cv.dnn.readNetFromCaffe(ageProto,ageModel)\n",
    "genderNet = cv.dnn.readNetFromCaffe(genderProto,genderModel)\n",
    "faceNet = cv.dnn.readNet(faceModel,faceProto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23602074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : Male, confidence = 1.000\n",
      "Age : (0-2), confidence = 0.751\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8e3bdac7bb98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Age Gender Demo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeFace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./detected/'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframeFace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time : {:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "# Open a video file or an image file or a camera stream\n",
    "cap = cv.VideoCapture(args.i if args.i else 0)\n",
    "padding = 20\n",
    "while cv.waitKey(1) < 0:\n",
    "    # Read frame\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame:\n",
    "        cv.waitKey()\n",
    "        break\n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "    if not bboxes:\n",
    "        print(\"No face Detected, Checking next frame\")\n",
    "        continue\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        # print(bbox)\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        blob = cv.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        \n",
    "        print(\"Gender : {}, confidence = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        \n",
    "        print(\"Age : {}, confidence = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv.putText(frameFace, label, (bbox[0]-5, bbox[1]-10), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0,255), 2, cv.LINE_AA)\n",
    "        cv.imshow(\"Age Gender Demo\", frameFace)\n",
    "        name = args.i\n",
    "        cv.imwrite('./detected/'+ name,frameFace)\n",
    "    print(\"Time : {:.3f}\".format(time.time() - t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ff461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
